{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 垃圾邮件文本分类v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data=[]\n",
    "    label=[]\n",
    "    with open(file_path,\"r\") as data_file:\n",
    "        raw_data=data_file.readlines()\n",
    "        for raw_line in raw_data:\n",
    "            sample=raw_line[:-1]#删除了行读取数据中的\\n\n",
    "            sample=sample.split(\",\")#以逗号分隔字符串\n",
    "            label.append(sample[-1])#记录末尾的布尔值\n",
    "            sample=np.array([float(feature) for feature in sample[:-1]])#创建一个array\n",
    "            sample[-3]/=10\n",
    "            sample[-2]/=100\n",
    "            sample[-1]/=1000\n",
    "            #对后三个较大的数据做调整\n",
    "            data.append(sample)#导出sample的值\n",
    "    return np.array(data),np.array(label)\n",
    "train_data,train_label=load_data(\"./train.data\")\n",
    "test_data,test_label=load_data(\"./test.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#序贯模型\n",
    "from tensorflow.keras import layers\n",
    "model = tf.keras.Sequential([\n",
    "layers.Dense(57, activation='softmax'),\n",
    "layers.Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3224 samples, validate on 1377 samples\n",
      "Epoch 1/40\n",
      "3224/3224 [==============================] - 2s 646us/step - loss: 0.6597 - acc: 0.7196 - val_loss: 0.6176 - val_acc: 0.8214\n",
      "Epoch 2/40\n",
      "3224/3224 [==============================] - 0s 50us/step - loss: 0.5790 - acc: 0.8567 - val_loss: 0.5266 - val_acc: 0.8903\n",
      "Epoch 3/40\n",
      "3224/3224 [==============================] - 0s 51us/step - loss: 0.4962 - acc: 0.8930 - val_loss: 0.4469 - val_acc: 0.9070\n",
      "Epoch 4/40\n",
      "3224/3224 [==============================] - 0s 52us/step - loss: 0.4271 - acc: 0.9060 - val_loss: 0.3843 - val_acc: 0.9223\n",
      "Epoch 5/40\n",
      "3224/3224 [==============================] - 0s 53us/step - loss: 0.3755 - acc: 0.9156 - val_loss: 0.3400 - val_acc: 0.9281\n",
      "Epoch 6/40\n",
      "3224/3224 [==============================] - 0s 52us/step - loss: 0.3393 - acc: 0.9228 - val_loss: 0.3089 - val_acc: 0.9317\n",
      "Epoch 7/40\n",
      "3224/3224 [==============================] - 0s 56us/step - loss: 0.3126 - acc: 0.9268 - val_loss: 0.2858 - val_acc: 0.9310\n",
      "Epoch 8/40\n",
      "3224/3224 [==============================] - 0s 55us/step - loss: 0.2917 - acc: 0.9296 - val_loss: 0.2678 - val_acc: 0.9339\n",
      "Epoch 9/40\n",
      "3224/3224 [==============================] - 0s 58us/step - loss: 0.2749 - acc: 0.9321 - val_loss: 0.2538 - val_acc: 0.9325\n",
      "Epoch 10/40\n",
      "3224/3224 [==============================] - 0s 56us/step - loss: 0.2613 - acc: 0.9327 - val_loss: 0.2424 - val_acc: 0.9332\n",
      "Epoch 11/40\n",
      "3224/3224 [==============================] - 0s 53us/step - loss: 0.2501 - acc: 0.9318 - val_loss: 0.2332 - val_acc: 0.9339\n",
      "Epoch 12/40\n",
      "3224/3224 [==============================] - 0s 53us/step - loss: 0.2404 - acc: 0.9330 - val_loss: 0.2250 - val_acc: 0.9354\n",
      "Epoch 13/40\n",
      "3224/3224 [==============================] - 0s 59us/step - loss: 0.2322 - acc: 0.9330 - val_loss: 0.2186 - val_acc: 0.9346\n",
      "Epoch 14/40\n",
      "3224/3224 [==============================] - 0s 62us/step - loss: 0.2251 - acc: 0.9339 - val_loss: 0.2130 - val_acc: 0.9354\n",
      "Epoch 15/40\n",
      "3224/3224 [==============================] - 0s 64us/step - loss: 0.2188 - acc: 0.9346 - val_loss: 0.2088 - val_acc: 0.9346\n",
      "Epoch 16/40\n",
      "3224/3224 [==============================] - 0s 55us/step - loss: 0.2134 - acc: 0.9364 - val_loss: 0.2048 - val_acc: 0.9354\n",
      "Epoch 17/40\n",
      "3224/3224 [==============================] - 0s 57us/step - loss: 0.2088 - acc: 0.9361 - val_loss: 0.2014 - val_acc: 0.9354\n",
      "Epoch 18/40\n",
      "3224/3224 [==============================] - ETA: 0s - loss: 0.2002 - acc: 0.939 - 0s 53us/step - loss: 0.2048 - acc: 0.9370 - val_loss: 0.1988 - val_acc: 0.9368\n",
      "Epoch 19/40\n",
      "3224/3224 [==============================] - 0s 58us/step - loss: 0.2010 - acc: 0.9373 - val_loss: 0.1962 - val_acc: 0.9375\n",
      "Epoch 20/40\n",
      "3224/3224 [==============================] - 0s 56us/step - loss: 0.1977 - acc: 0.9398 - val_loss: 0.1944 - val_acc: 0.9375\n",
      "Epoch 21/40\n",
      "3224/3224 [==============================] - 0s 55us/step - loss: 0.1946 - acc: 0.9398 - val_loss: 0.1919 - val_acc: 0.9375\n",
      "Epoch 22/40\n",
      "3224/3224 [==============================] - 0s 57us/step - loss: 0.1919 - acc: 0.9398 - val_loss: 0.1900 - val_acc: 0.9368\n",
      "Epoch 23/40\n",
      "3224/3224 [==============================] - 0s 57us/step - loss: 0.1891 - acc: 0.9395 - val_loss: 0.1887 - val_acc: 0.9361\n",
      "Epoch 24/40\n",
      "3224/3224 [==============================] - 0s 58us/step - loss: 0.1866 - acc: 0.9392 - val_loss: 0.1874 - val_acc: 0.9375\n",
      "Epoch 25/40\n",
      "3224/3224 [==============================] - 0s 58us/step - loss: 0.1842 - acc: 0.9398 - val_loss: 0.1857 - val_acc: 0.9368\n",
      "Epoch 26/40\n",
      "3224/3224 [==============================] - 0s 56us/step - loss: 0.1820 - acc: 0.9414 - val_loss: 0.1845 - val_acc: 0.9375\n",
      "Epoch 27/40\n",
      "3224/3224 [==============================] - 0s 56us/step - loss: 0.1799 - acc: 0.9408 - val_loss: 0.1829 - val_acc: 0.9375\n",
      "Epoch 28/40\n",
      "3224/3224 [==============================] - 0s 53us/step - loss: 0.1777 - acc: 0.9429 - val_loss: 0.1818 - val_acc: 0.9390\n",
      "Epoch 29/40\n",
      "3224/3224 [==============================] - 0s 51us/step - loss: 0.1758 - acc: 0.9435 - val_loss: 0.1806 - val_acc: 0.9397\n",
      "Epoch 30/40\n",
      "3224/3224 [==============================] - 0s 51us/step - loss: 0.1738 - acc: 0.9435 - val_loss: 0.1790 - val_acc: 0.9390\n",
      "Epoch 31/40\n",
      "3224/3224 [==============================] - 0s 52us/step - loss: 0.1718 - acc: 0.9454 - val_loss: 0.1773 - val_acc: 0.9405\n",
      "Epoch 32/40\n",
      "3224/3224 [==============================] - 0s 58us/step - loss: 0.1694 - acc: 0.9463 - val_loss: 0.1766 - val_acc: 0.9390\n",
      "Epoch 33/40\n",
      "3224/3224 [==============================] - 0s 56us/step - loss: 0.1683 - acc: 0.9470 - val_loss: 0.1756 - val_acc: 0.9397\n",
      "Epoch 34/40\n",
      "3224/3224 [==============================] - 0s 62us/step - loss: 0.1664 - acc: 0.9473 - val_loss: 0.1748 - val_acc: 0.9390\n",
      "Epoch 35/40\n",
      "3224/3224 [==============================] - 0s 59us/step - loss: 0.1651 - acc: 0.9476 - val_loss: 0.1744 - val_acc: 0.9412\n",
      "Epoch 36/40\n",
      "3224/3224 [==============================] - 0s 61us/step - loss: 0.1634 - acc: 0.9485 - val_loss: 0.1740 - val_acc: 0.9412\n",
      "Epoch 37/40\n",
      "3224/3224 [==============================] - 0s 56us/step - loss: 0.1621 - acc: 0.9488 - val_loss: 0.1733 - val_acc: 0.9412\n",
      "Epoch 38/40\n",
      "3224/3224 [==============================] - 0s 56us/step - loss: 0.1608 - acc: 0.9488 - val_loss: 0.1729 - val_acc: 0.9405\n",
      "Epoch 39/40\n",
      "3224/3224 [==============================] - 0s 56us/step - loss: 0.1594 - acc: 0.9491 - val_loss: 0.1724 - val_acc: 0.9412\n",
      "Epoch 40/40\n",
      "3224/3224 [==============================] - 0s 60us/step - loss: 0.1584 - acc: 0.9501 - val_loss: 0.1721 - val_acc: 0.9405\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,#训练数据\n",
    "                    train_label,#训练标识，有监督学习\n",
    "                    epochs=40,#训练轮数\n",
    "                    batch_size=20,\n",
    "                    validation_data=(test_data, test_label),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flag 图\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.array(range(560))\n",
    "y = forcase_end\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 6]\n",
      "[3 7]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
